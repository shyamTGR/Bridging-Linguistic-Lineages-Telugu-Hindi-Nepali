{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":85416,"databundleVersionId":9690815,"sourceType":"competition"},{"sourceId":10437264,"sourceType":"datasetVersion","datasetId":6462423},{"sourceId":85986,"sourceType":"modelInstanceVersion","modelInstanceId":72246,"modelId":78150},{"sourceId":228526,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":194870,"modelId":216770},{"sourceId":228542,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":194881,"modelId":216781}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-13T11:57:59.494021Z","iopub.execute_input":"2025-01-13T11:57:59.494277Z","iopub.status.idle":"2025-01-13T11:57:59.511512Z","shell.execute_reply.started":"2025-01-13T11:57:59.494248Z","shell.execute_reply":"2025-01-13T11:57:59.510338Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/supervised-finetuned-weights/jax/default/1/lora_weights_epoch3.lora.h5\n/kaggle/input/gemma-language-tuning/submission_instructions.txt\n/kaggle/input/multilingual-text-corpus/multilingual_corpus_with_tags_reordered.txt\n/kaggle/input/kaggleinputsupervised-finetuned-weightsjax/jax/default/1/lora_weights_epoch1.lora.h5\n/kaggle/input/gemma2/keras/gemma2_instruct_2b_en/1/config.json\n/kaggle/input/gemma2/keras/gemma2_instruct_2b_en/1/tokenizer.json\n/kaggle/input/gemma2/keras/gemma2_instruct_2b_en/1/metadata.json\n/kaggle/input/gemma2/keras/gemma2_instruct_2b_en/1/model.weights.h5\n/kaggle/input/gemma2/keras/gemma2_instruct_2b_en/1/assets/tokenizer/vocabulary.spm\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Install Keras 3 last. See https://keras.io/getting_started/ for more details.\n!pip install -q -U keras-nlp datasets\n!pip install -q -U keras\n\nimport os\n\n# Set the backbend before importing Keras\nos.environ[\"KERAS_BACKEND\"] = \"jax\"\n# Avoid memory fragmentation on JAX backend.\nos.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"1.00\"\n\nimport keras_nlp\nimport keras\n\n# Run at half precision.\n#keras.config.set_floatx(\"bfloat16\")\n\n# Training Configurations\ntoken_limit = 1024\nlora_name = \"arya\"\nlora_rank = 4\nlr_value = 1e-4\ntrain_epoch = 20\nmodel_id = \"gemma2_instruct_2b_en\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T08:38:37.848616Z","iopub.execute_input":"2025-01-11T08:38:37.849121Z","iopub.status.idle":"2025-01-11T08:38:48.164733Z","shell.execute_reply.started":"2025-01-11T08:38:37.849085Z","shell.execute_reply":"2025-01-11T08:38:48.163970Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import keras\nimport keras_nlp\n\nimport time\n\ngemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(model_id)\ngemma_lm.summary()\n\ntick_start = 0\n\ndef tick():\n    global tick_start\n    tick_start = time.time()\n\ndef tock():\n    print(f\"TOTAL TIME ELAPSED: {time.time() - tick_start:.2f}s\")\n\ndef text_gen(prompt):\n    tick()\n    input = f\"<start_of_turn>user\\n{prompt}<end_of_turn>\\n<start_of_turn>model\\n\"\n    output = gemma_lm.generate(input, max_length=token_limit)\n    print(\"\\nGemma output:\")\n    print(output)\n    tock()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T08:38:48.165868Z","iopub.execute_input":"2025-01-11T08:38:48.166439Z","iopub.status.idle":"2025-01-11T08:39:32.909430Z","shell.execute_reply.started":"2025-01-11T08:38:48.166415Z","shell.execute_reply":"2025-01-11T08:39:32.908509Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                              │                      Vocab size: \u001b[38;5;34m256,000\u001b[0m │\n└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                                                  </span>┃<span style=\"font-weight: bold\">                                   Config </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                              │                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)        │   \u001b[38;5;34m2,614,341,888\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m589,824,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,614,341,888\u001b[0m (9.74 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> (9.74 GB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,614,341,888\u001b[0m (9.74 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> (9.74 GB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"# Running Intereference with the three languages before fine tuning","metadata":{}},{"cell_type":"code","source":"text_gen(\"వెళ్ళిపోతూ మళ్లీ వస్తానని అన్నాడు. కానీ, అతను తిరిగి రాలేదు. అతని గురించి ఏం అనిపిస్తోంది?\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"text_gen(\"उसने कहा था कि वो लौटकर आएगा, लेकिन वो वापस नहीं आया। उसके बारे में आपको क्या लगता है?\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"text_gen(\"उहाँले फर्किन्छु भन्नु भयो, तर उहाँ फर्किनु भएन। तपाईंलाई उहाँबारे के लाग्छ?\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import keras\nimport keras_nlp\nfrom datasets import load_dataset\n\n# Load Gemma tokenizer\nmodel_id = \"gemma2_instruct_2b_en\"\ntokenizer = keras_nlp.models.GemmaTokenizer.from_preset(model_id)\n\n# Configuration\ntoken_limit = 256  # Maximum token length\nnum_data_limit = 1000  # Limit on the number of examples to process\n\n# Language tags mapping\nlanguage_tags = {\n     \"san\":\"sanskrit\",\n    \"tel\":\"telugu\",\n    \"hin\":\"hindi\",\n    \"npi\":\"nepali\"\n}\n\n# Load dataset\ndataset_path = \"/kaggle/input/multilingual-text-corpus/multilingual_corpus_with_tags_reordered.txt\"\nraw_dataset = load_dataset(\"text\", data_files={\"train\": dataset_path})\n\n# Prepare dataset for fine-tuning\ntrain_data = []\n\n# Loop through the dataset and tokenize\nfor example in raw_dataset[\"train\"]:\n    text = example[\"text\"]\n    \n    # Extract the language tag (example assumes the language is in the first part of the text)\n    # Example: \"<tel> This is a Telugu sentence.\"\n    language = text.split(\">\")[0][1:]  # Extract \"tel\" from \"<tel>\"\n    tag = language_tags.get(language, \"<unk>\")  # Use <unk> for unknown languages\n    #print(language)\n    # Add language tag explicitly\n    tagged_text = f\"{tag} {text}\"\n\n    # Tokenize the text\n    tokenized = tokenizer.tokenize(tagged_text)  # Tokenize the tagged text\n    token_length = len(tokenized)  # Get the length of the tokenized sequence\n    \n    # Filter long sequences and add to training data\n    if token_length < token_limit:\n        train_data.append(tagged_text)\n    \n\n\n# Output dataset stats and examples\nprint(f\"Number of training examples: {len(train_data)}\")\nprint(f\"First example:\\n{train_data[0]}\")\nprint(f\"Second example:\\n{train_data[1]}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T08:40:06.892914Z","iopub.execute_input":"2025-01-11T08:40:06.893245Z","iopub.status.idle":"2025-01-11T08:42:51.163705Z","shell.execute_reply.started":"2025-01-11T08:40:06.893220Z","shell.execute_reply":"2025-01-11T08:42:51.162894Z"}},"outputs":[{"name":"stdout","text":"Number of training examples: 97573\nFirst example:\nsanskrit <san> स्वदेहे चेल्लिखितवान्वचनमनवगम्यं तेनाप्यचिन्तिते फल उपलब्धे किं कर्तव्यम् ?\nSecond example:\nsanskrit <san> तत्त्वमसि ।\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Enable LoRA (Low-Rank Adaptation)\nlora_rank = 4  # LoRA rank\ngemma_lm.backbone.enable_lora(rank=lora_rank)\ngemma_lm.preprocessor.sequence_length = token_limit\n\n# Configure the optimizer\noptimizer = keras.optimizers.AdamW(\n    learning_rate=lr_value,\n    weight_decay=0.01,\n)\noptimizer.exclude_from_weight_decay(var_names=[\"bias\", \"scale\"])\n\ngemma_lm.compile(\n    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    optimizer=optimizer,\n    weighted_metrics=[keras.metrics.SparseCategoricalAccuracy()],\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T08:43:56.894385Z","iopub.execute_input":"2025-01-11T08:43:56.894691Z","iopub.status.idle":"2025-01-11T08:43:56.903592Z","shell.execute_reply.started":"2025-01-11T08:43:56.894665Z","shell.execute_reply":"2025-01-11T08:43:56.902688Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"class SaveLoRAWeightsCallback(keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs=None):\n        lora_weights_path = f\"/kaggle/working/lora_weights_epoch{epoch + 1}.lora.h5\"\n        gemma_lm.backbone.save_lora_weights(lora_weights_path)\n        print(f\"Saved LoRA weights to: {lora_weights_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T08:43:59.160288Z","iopub.execute_input":"2025-01-11T08:43:59.160643Z","iopub.status.idle":"2025-01-11T08:43:59.165463Z","shell.execute_reply.started":"2025-01-11T08:43:59.160599Z","shell.execute_reply":"2025-01-11T08:43:59.164549Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Fine-tune the model\nepochs = 10\nbatch_size = 8\n\ngemma_lm.fit(\n    train_data,  # The tokenized dataset\n    epochs=epochs,\n    batch_size=batch_size,\n    callbacks=[SaveLoRAWeightsCallback()],\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nimport keras_nlp\nimport keras\n\n# Mount Google Drive\n\n\n# Load Gemma 2 model\nmodel_id = \"gemma2_instruct_2b_en\"\ngemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(model_id)\n\n# Enable LoRA and load weights\nlora_rank = 4\ngemma_lm.backbone.enable_lora(rank=lora_rank)\nlora_weights_path = \"/kaggle/input/kaggleinputsupervised-finetuned-weightsjax/jax/default/1/lora_weights_epoch3.lora.h5\"\ngemma_lm.backbone.load_lora_weights(lora_weights_path)\n\nprint(\"LoRA weights loaded successfully.\")\ngemma_lm.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T11:59:46.466108Z","iopub.execute_input":"2025-01-13T11:59:46.466384Z","iopub.status.idle":"2025-01-13T12:00:52.170473Z","shell.execute_reply.started":"2025-01-13T11:59:46.466361Z","shell.execute_reply":"2025-01-13T12:00:52.169852Z"}},"outputs":[{"name":"stdout","text":"LoRA weights loaded successfully.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                              │                      Vocab size: \u001b[38;5;34m256,000\u001b[0m │\n└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                                                  </span>┃<span style=\"font-weight: bold\">                                   Config </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                              │                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)        │   \u001b[38;5;34m2,617,270,528\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m589,824,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,617,270,528</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,617,270,528\u001b[0m (9.75 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,617,270,528</span> (9.75 GB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,928,640\u001b[0m (11.17 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,928,640</span> (11.17 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,614,341,888\u001b[0m (9.74 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> (9.74 GB)\n</pre>\n"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"import json\n\n# Load translation dataset\njson_path = \"/content/drive/MyDrive/Translations_Multilingual.json\"\nwith open(json_path, \"r\", encoding=\"utf-8\") as f:\n    translation_data = json.load(f)\n\n# Configuration\ntoken_limit = 1024\ntrain_data = []\n\n# Prepare data for fine-tuning\nfor example in translation_data[0]:  # Assuming the JSON is a list of dictionaries\n    prompt = example[\"prompt\"]\n    response = example[\"response\"]\n    #print(f\"Prompt: {prompt}\")\n\n    # Prepare input-output text format for supervised learning\n    input_text = f\"<start_of_turn>user\\n{prompt}<end_of_turn>\\n<start_of_turn>model\\n{response}<end_of_turn>\"\n\n    # Tokenize the text using the preprocessor\n    tokenized = gemma_lm.preprocessor(input_text)  # Returns a tuple\n\n    # Extract token_ids and attention mask\n    token_ids = tokenized[0][\"token_ids\"]\n    #print(f\"Token IDs: {token_ids.numpy()}\")\n    #print(len(token_ids))\n    # Filter long sequences based on token length\n    if len(token_ids) <= token_limit:\n        train_data.append(input_text)\n\n# Display dataset stats\nprint(f\"Number of training examples: {len(train_data)}\")\nif len(train_data) > 0:\n    print(f\"First example:\\n{train_data[0]}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\n\n# Save tokenized training data\ntokenized_data_path = \"/content/drive/MyDrive/Tokenized_Translations.json\"\nwith open(tokenized_data_path, \"w\", encoding=\"utf-8\") as f:\n    json.dump(train_data, f, ensure_ascii=False, indent=4)\n\nprint(f\"Tokenized data saved to: {tokenized_data_path}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\ntokenized_data_path = \"/content/drive/MyDrive/Tokenized_Translations.json\"\nwith open(tokenized_data_path, \"r\", encoding=\"utf-8\") as f:\n    train_data = json.load(f)\n\nprint(f\"Tokenized data loaded successfully. Number of examples: {len(train_data)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T12:00:59.008206Z","iopub.execute_input":"2025-01-13T12:00:59.008801Z","iopub.status.idle":"2025-01-13T12:00:59.013608Z","shell.execute_reply.started":"2025-01-13T12:00:59.008770Z","shell.execute_reply":"2025-01-13T12:00:59.012680Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"token_limit=1024\ntext_gen(\"Translate to Hindi: The sun rises in the east.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T12:10:34.706784Z","iopub.execute_input":"2025-01-13T12:10:34.707066Z","iopub.status.idle":"2025-01-13T12:11:08.500473Z","shell.execute_reply.started":"2025-01-13T12:10:34.707045Z","shell.execute_reply":"2025-01-13T12:11:08.499509Z"}},"outputs":[{"name":"stdout","text":"\nGemma output:\n<start_of_turn>user\nTranslate to telugu: The sun rises in the east.<end_of_turn>\n<start_of_turn>model\nसूरज पूर्व में उगता है।<end_of_turn>\nTOTAL TIME ELAPSED: 33.79s\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"text_gen(\"Tell a story in hindi\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T12:09:02.472653Z","iopub.execute_input":"2025-01-13T12:09:02.472946Z","iopub.status.idle":"2025-01-13T12:09:07.404756Z","shell.execute_reply.started":"2025-01-13T12:09:02.472923Z","shell.execute_reply":"2025-01-13T12:09:07.403865Z"}},"outputs":[{"name":"stdout","text":"\nGemma output:\n<start_of_turn>user\nTell a story in hindi<end_of_turn>\n<start_of_turn>model\nएक दिन, एक बूढ़ा मनुष्य, जो अपने जीवन में बहुत ही दुखी था, ने एक बूढ़ी बिल्ली को देखा, जो अपने बच्चे को खाने के लिये चिल्ला रही थी। उस मनुष्य ने बिल्ली को समझाया, कि तू अपने बच्चे को खाने के लिये चिल्लाती है, पर वह तुझे खाने के लिये नहीं चिल्लाती। बिल्ली ने उस मनुष्य को उत्तर दिया, कि मैं तुझे खाने के लिये नहीं चिल्लाती, पर मैं तुझे अपने बच्चे को खाने के लिये चिल्लाती हूं।<end_of_turn>\nTOTAL TIME ELAPSED: 4.93s\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}